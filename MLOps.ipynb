{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMBO Gaussian Process - New York City Taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nyc_taxi.csv\").iloc[:, 1:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pickup_datetime'] = data['pickup_datetime'].str.slice(0, 16)\n",
    "data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations with missing values\n",
    "# Since there are only a few of these, i'm not concerned with imputation\n",
    "data.dropna(how='any', axis='rows', inplace=True)\n",
    "\n",
    "# Removing observations with erroneous values\n",
    "mask = data['pickup_longitude'].between(-75, -73)\n",
    "mask &= data['dropoff_longitude'].between(-75, -73)\n",
    "mask &= data['pickup_latitude'].between(40, 42)\n",
    "mask &= data['dropoff_latitude'].between(40, 42)\n",
    "mask &= data['passenger_count'].between(0, 8)\n",
    "mask &= data['fare_amount'].between(0, 250)\n",
    "\n",
    "data = data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Implémenter la distance de Manhattan (norme L1)\n",
    "def dist(pickup_lat, pickup_long, dropoff_lat, dropoff_long):  \n",
    "    distance = # ...\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    # Extract date attributes and then drop the pickup_datetime column\n",
    "    data['hour'] = data['pickup_datetime'].dt.hour\n",
    "    data['day'] = data['pickup_datetime'].dt.day\n",
    "    data['month'] = data['pickup_datetime'].dt.month\n",
    "    data['year'] = data['pickup_datetime'].dt.year\n",
    "    data = data.drop('pickup_datetime', axis=1)\n",
    "\n",
    "    # Distances to nearby airports, and city center\n",
    "    # By reporting distances to these points, the model can somewhat triangulate other locations of interest\n",
    "    nyc = (-74.0063889, 40.7141667)\n",
    "    jfk = (-73.7822222222, 40.6441666667)\n",
    "    ewr = (-74.175, 40.69)\n",
    "    lgr = (-73.87, 40.77)\n",
    "    data['distance_to_center'] = dist(nyc[1], nyc[0],\n",
    "                                      data['pickup_latitude'], data['pickup_longitude'])\n",
    "    data['pickup_distance_to_jfk'] = dist(jfk[1], jfk[0],\n",
    "                                         data['pickup_latitude'], data['pickup_longitude'])\n",
    "    data['dropoff_distance_to_jfk'] = dist(jfk[1], jfk[0],\n",
    "                                           data['dropoff_latitude'], data['dropoff_longitude'])\n",
    "    data['pickup_distance_to_ewr'] = dist(ewr[1], ewr[0], \n",
    "                                          data['pickup_latitude'], data['pickup_longitude'])\n",
    "    data['dropoff_distance_to_ewr'] = dist(ewr[1], ewr[0],\n",
    "                                           data['dropoff_latitude'], data['dropoff_longitude'])\n",
    "    data['pickup_distance_to_lgr'] = dist(lgr[1], lgr[0],\n",
    "                                          data['pickup_latitude'], data['pickup_longitude'])\n",
    "    data['dropoff_distance_to_lgr'] = dist(lgr[1], lgr[0],\n",
    "                                           data['dropoff_latitude'], data['dropoff_longitude'])\n",
    "    \n",
    "    data['long_dist'] = data['pickup_longitude'] - data['dropoff_longitude']\n",
    "    data['lat_dist'] = data['pickup_latitude'] - data['dropoff_latitude']\n",
    "    \n",
    "    data['dist'] = dist(data['pickup_latitude'], data['pickup_longitude'],\n",
    "                        data['dropoff_latitude'], data['dropoff_longitude'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "dataset = transform(data)\n",
    "dataset = dataset.drop(['key'], axis=1)\n",
    "dataset = dataset.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop('fare_amount', axis=1),\n",
    "                                                    dataset['fare_amount'], test_size=0.25)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation bayésienne des hyper-paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimisation de la fonction de perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, gamma, colsample_bytree, nrounds):\n",
    "    params = {'eval_metric': 'rmse',\n",
    "              'objective':'reg:squarederror',\n",
    "              'max_depth': int(max_depth),\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'nrounds': int(nrounds)}\n",
    "    \n",
    "    # Used around 1000 boosting rounds in the full model\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3, metrics=['rmse'])    \n",
    "    \n",
    "    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n",
    "    return -cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 7), \n",
    "                                             'gamma': (0, 1),\n",
    "                                             'colsample_bytree': (0.3, 0.9),\n",
    "                                             'nrounds': (100, 1000)})\n",
    "# Use the expected improvement acquisition function to handle negative numbers\n",
    "# Optimally needs quite a few more initiation points and number of iterations\n",
    "xgb_bo.maximize(init_points=3, n_iter=10, acq='ei')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle optimisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Entraîner un modèle avec le jeu d'hyper-paramètres optimal\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
